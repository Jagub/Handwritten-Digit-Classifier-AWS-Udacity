{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets==7.4.2\n",
      "  Downloading ipywidgets-7.4.2-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.4.2) (5.0.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.4.2) (5.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.4.2) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.4.2) (7.13.0)\n",
      "Collecting widgetsnbextension~=3.4.0\n",
      "  Downloading widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (3.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2) (6.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets==7.4.2) (1.16.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets==7.4.2) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (45.2.0.post20200209)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (3.0.3)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.16.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.1.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (5.7.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.4.2) (19.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.4.2) (2.8.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (2.11.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.7.1)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.8.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (5.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.1.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (3.1.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.4.2)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.5.1)\n",
      "Installing collected packages: widgetsnbextension, ipywidgets\n",
      "Successfully installed ipywidgets-7.4.2 widgetsnbextension-3.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets==7.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "## YOUR CODE HERE ##\n",
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "## YOUR CODE HERE ##\n",
    "train_data=torchvision.datasets.MNIST(root=\"data\",train=True,download=True,transform=transform)\n",
    "\n",
    "valid_data=torchvision.datasets.MNIST(root=\"data\",train=False,download=True,transform=transform)\n",
    "# Create test set and define test dataloader\n",
    "## YOUR CODE HERE ##\n",
    "test_data=torchvision.datasets.MNIST(root=\"data\",train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\n",
    "validloader=torch.utils.data.DataLoader(valid_data,batch_size=16,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(test_data,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the images in the MNIST dataset have a size of 28x28 pixels. Therefore, there is no need for resizing or reshaping the images before feeding them into the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "torch.Size([28, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "print(train_size)\n",
    "test_size  = len(test_data)\n",
    "print(test_size)\n",
    "train_shape = train_data.data[0].shape\n",
    "print(train_shape)\n",
    "test_shape =  test_data.data[0].shape\n",
    "print(test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show5(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "hidden_layer_1=128\n",
    "class NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,hidden_layer_1)\n",
    "        self.fc2 = nn.Linear(hidden_layer_1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net=NET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "lr=0.01\n",
    "optimizer=optim.Adam(net.parameters(),lr=lr)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3   Training loss: 0.2771   validation loss: 0.2011   valid accuracy: 0.9460  \n",
      "Epoch: 2/3   Training loss: 0.2002   validation loss: 0.2173   valid accuracy: 0.9474  \n",
      "Epoch: 3/3   Training loss: 0.1881   validation loss: 0.1907   valid accuracy: 0.9521  \n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for idx, (images, labels) in enumerate(trainloader): \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    validaccuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validloader:     \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)   \n",
    "            outputs1 = net(images)\n",
    "            valid_loss += criterion(outputs1, labels)\n",
    "            probabilities = torch.exp(outputs1)\n",
    "            top_prob, top_class = probabilities.topk(1, dim=1)\n",
    "            predictions = top_class == labels.view(*top_class.shape)\n",
    "            validaccuracy += torch.mean(predictions.type(torch.FloatTensor))\n",
    "        \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "        \n",
    "    print(\"Epoch: {}/{}  \".format(epoch+1, epochs),\n",
    "          \"Training loss: {:.4f}  \".format(train_loss/len(trainloader)),\n",
    "          \"validation loss: {:.4f}  \".format(valid_loss/len(validloader)),\n",
    "          \"valid accuracy: {:.4f}  \".format(validaccuracy/len(validloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:95.21 %\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "test_accuracy=0\n",
    "with torch.no_grad():\n",
    "    for test_images,test_labels in testloader:\n",
    "        net.eval()\n",
    "        test_images=test_images.to(device)\n",
    "        test_labels=test_labels.to(device)\n",
    "   \n",
    "        test_outputs=net.forward(test_images)\n",
    "        test_loss=criterion(test_outputs,test_labels)\n",
    "        ps=torch.exp(test_outputs)\n",
    "        top_p,top_class=ps.topk(1,dim=1)\n",
    "        equals=top_class==test_labels.view(*top_class.shape)\n",
    "        test_accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    \n",
    "    print(\"test accuracy:{:.2f} %\".format(test_accuracy/len(testloader)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1=512\n",
    "hidden_layer_2=64\n",
    "class NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, padding=1, stride=1)\n",
    "        self.fc1 = nn.Linear(24*7*7, hidden_layer_1)\n",
    "        self.fc2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.fc3 = nn.Linear(hidden_layer_2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net=NET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer=optim.SGD(net.parameters(),lr=lr)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NET(\n",
       "  (conv1): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1176, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15   Training loss: 0.3110   validation loss: 0.2772   valid accuracy: 0.9172  \n",
      "Epoch: 2/15   Training loss: 0.2663   validation loss: 0.2309   valid accuracy: 0.9293  \n",
      "Epoch: 3/15   Training loss: 0.2306   validation loss: 0.1974   valid accuracy: 0.9405  \n",
      "Epoch: 4/15   Training loss: 0.2009   validation loss: 0.1688   valid accuracy: 0.9479  \n",
      "Epoch: 5/15   Training loss: 0.1774   validation loss: 0.1488   valid accuracy: 0.9548  \n",
      "Epoch: 6/15   Training loss: 0.1582   validation loss: 0.1381   valid accuracy: 0.9569  \n",
      "Epoch: 7/15   Training loss: 0.1430   validation loss: 0.1187   valid accuracy: 0.9631  \n",
      "Epoch: 8/15   Training loss: 0.1296   validation loss: 0.1144   valid accuracy: 0.9660  \n",
      "Epoch: 9/15   Training loss: 0.1189   validation loss: 0.1088   valid accuracy: 0.9662  \n",
      "Epoch: 10/15   Training loss: 0.1097   validation loss: 0.0953   valid accuracy: 0.9699  \n",
      "Epoch: 11/15   Training loss: 0.1023   validation loss: 0.0901   valid accuracy: 0.9712  \n",
      "Epoch: 12/15   Training loss: 0.0960   validation loss: 0.0899   valid accuracy: 0.9719  \n",
      "Epoch: 13/15   Training loss: 0.0900   validation loss: 0.0858   valid accuracy: 0.9738  \n",
      "Epoch: 14/15   Training loss: 0.0852   validation loss: 0.0749   valid accuracy: 0.9750  \n",
      "Epoch: 15/15   Training loss: 0.0808   validation loss: 0.0736   valid accuracy: 0.9773  \n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for idx, (images, labels) in enumerate(trainloader): \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    validaccuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validloader:     \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)   \n",
    "            outputs1 = net(images)\n",
    "            valid_loss += criterion(outputs1, labels)\n",
    "            probabilities = torch.exp(outputs1)\n",
    "            top_prob, top_class = probabilities.topk(1, dim=1)\n",
    "            predictions = top_class == labels.view(*top_class.shape)\n",
    "            validaccuracy += torch.mean(predictions.type(torch.FloatTensor))\n",
    "        \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "        \n",
    "    print(\"Epoch: {}/{}  \".format(epoch+1, epochs),\n",
    "          \"Training loss: {:.4f}  \".format(train_loss/len(trainloader)),\n",
    "          \"validation loss: {:.4f}  \".format(valid_loss/len(validloader)),\n",
    "          \"valid accuracy: {:.4f}  \".format(validaccuracy/len(validloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "test_accuracy=0\n",
    "with torch.no_grad():\n",
    "    for test_images,test_labels in testloader:\n",
    "        net.eval()\n",
    "        test_images=test_images.to(device)\n",
    "        test_labels=test_labels.to(device)\n",
    "   \n",
    "        test_outputs=net.forward(test_images)\n",
    "        test_loss=criterion(test_outputs,test_labels)\n",
    "        ps=torch.exp(test_outputs)\n",
    "        top_p,top_class=ps.topk(1,dim=1)\n",
    "        equals=top_class==test_labels.view(*top_class.shape)\n",
    "        test_accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    \n",
    "    print(\"test accuracy:{:.2f} %\".format(test_accuracy/len(testloader)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "net.class_to_idx=train_data.class_to_idx\n",
    "torch.save({\"hidden_layer1\":512,\n",
    "            \"hidden_layer2\":64,\n",
    "            \"output_layer\":10,\n",
    "            \"gpu\":device,\n",
    "            \"lr\":0.001,\n",
    "            \"epochs\":15,\n",
    "            \"state_dict\":net.state_dict(),\n",
    "            \"class_to_idx\":net.class_to_idx,\n",
    "            \"optimizer_dict\":optimizer.state_dict()},\n",
    "            \"checkpoint.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
